\documentclass[UTF8]{article}


% if you need to pass options to natbib，use，e.g.：
%     \PassOptionsToPackage{numbers，compress}{natbib}
% before loading neurips_2022


% ready for submission
\usepackage[final]{neurips_2022_zh}

% \PassOptionsToPackage{numbers，compress}{natbib}


% to compile a preprint version，e.g.，for submission to arXiv，add add the
% [preprint] option：
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version，add the [final] option，e.g.：
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package，add option nonatbib：
%    \usepackage[nonatbib]{neurips_2022}

\usepackage{ctex} % support zh
\usepackage{indentfirst} %support indent
\usepackage{graphicx} % support image
\usepackage[colorlinks, linkcolor=blue]{hyperref}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2，etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\setlength{\parindent}{2em}
\title{动态局部可搜索对称加密}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors： \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So，if LaTeX puts 3 of 4
% authors names on the first line，and the last on the second line，try using
% \AND instead of \And before the third author name.


\author{%
  肖泽宇\thanks{本文是对Crypto2022 "Dynamic Local Searchable Symmetric Encryption"的翻译，不包含附录部分，因此调整了正文的部分内容}\thanks{参考原文链接 https://hal.archives-ouvertes.fr/hal-03863896/document} \\
  \texttt{2022202210145} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
  在这篇文章中，我们将首次解决动态的内存高效的可搜索对称加密问题(SSE)。这里的术语“内存高效”包括局部内存高效和页内存高效。我们方法的核心是在这两个目标之间建立一种新型的联系。我们引入了一个被称为泛型局部变换的映射，它将具有某些特殊特征的高效页SSE方案作为输入，并输出具有强局域性的SSE方案。我们得到了以下几个结果。
  \begin{itemize}
    \item 首先，对于页面高效SSE，我们构建了一个页面效率O(log log N)和存储效率O(1)的动态方案，称为LayeredSSE。LayeredSSE背后的主要技术创新是较为独立的双选分配(2-choice)过程的一种新的加权扩展。
    \item 其次，引入了泛型局部变换，并将其与LayeredSSE相结合，在最长列表大小为$\mathcal{O}\left(N^{1-1 / \log \log \lambda}\right)$的条件下，构建存储效率O(1)，局域性O(1)，读取效率O(log log N)的动态SSE方案。这在各方面都与Asharov等人在STOC 2016上提出的纯静态结构相匹配:动态性无需额外成本。
    \item 最后，通过将通用局部变换应用于Bossuat等人从Crypto 2021提出的Tethys方案的变体，我们构建了一个无条件静态SSE，其存储效率O(1)， 局域性(1)，读取效率$\mathcal{O}\left(\log ^{\varepsilon} N\right)$，对于任意小的常数$\varepsilon$ > 0。据我们所知，这是Cash和Tessaro在2014年的Eurocrypt会议上提出的最接近下限的结构。
  \end{itemize}
\end{abstract}


\section{简介}
\textbf{可搜索对称加密。}在可搜索对称加密(SSE)中，客户端将一组文档的存储托管给不受信任的服务器。客户端能向服务器发出搜索请求来执行搜索。在动态SSE的问题假设中，客户端还可以发出更新请求，以修改文档的内容，例如添加或删除条目。服务器必须能够正确地处理所有请求，同时尽可能少地了解文档数据和请求的信息。SSE与许多云存储场景相关:例如，在托管敏感数据库或提供加密消息传递服务等情况下，搜索功能十分必要。

理论上，SSE是加密数据计算的一种特殊情况，可以使用通用的解决方案来实现，例如完全同态加密。但在实践中，这种方法会导致很大的性能损失。因此，SSE方案通常以高性能解决方案为目标，可扩展到大型真实场景数据库。为此，SSE不惜以安全换取效率。服务器被允许了解一些客户端数据的信息。例如，SSE方案通常向服务器泄漏查询的搜索模式和与查询匹配的文档标识符，或者说访问模式。SSE的安全模型通过泄漏函数进行量化，该函数评估泄漏给服务器的信息的性质。

\textbf{定位。}对于单关键字SSE，搜索请求要求返回包含给定关键字的所有文档。为了实现该功能，服务器维护一个加密的反向索引，其中每个关键字都映射到与之匹配的文档的标识符列表。当客户希望搜索包含给定关键字的文档时，只需从服务器检索相应的列表。然而，一个关键的问题是服务器应该如何存储和访问列表。

一个列表接一个列表存储的简单方法并不令人满意:实际上，给定列表在内存中的位置依赖于其他列表的长度，从而泄露了关于这些列表的信息。解决这个问题的常用方法是将每个列表元素存储在内存中的随机位置。在这种情况下，当检索列表时，服务器必须访问与列表中元素数量一样多的随机内存位置。这也是不可取的，性能太差:对于几乎所有的现代存储介质，访问随机内存位置比访问一个连续区域要慢得多。由于SSE依赖于快速对称密码学方法，内存访问成本成为性能瓶颈。为了降低成本，\cite{DavidCash2014TheLO}引入了局部性的概念:简而言之，一种SSE方案的局部性，可以由服务器响应查询请求所必须访问的不连续内存位置的数量来评估。

上面概述的两个极端解决方案表明安全性和局部性之间存在冲突。在Eurocrypt 2014会议上，Cash和Tessaro表明这种冲突是固有的\cite{DavidCash2014TheLO}:如果安全SSE方案具有恒定的存储效率(加密数据库的大小与明文数据库的大小成线性关系)和恒定的读取效率(服务器响应搜索请求而读取的数据量与明文答案的大小成线性关系)，那么它不可能具有恒定的局域性指标。

\textbf{局部SSE结构。}从2014年以后，许多具有定域性的SSE方案被提出，通常是以读取效率为代价的。在STOC 2016上，Asharov等人提出了一种具有O(1)存储效率、O(1)局部性和O(log N)读取效率的方案，其中N是数据库的大小\cite{GiladAsharov2021SearchableSE}。在Crypto 2018上，Demertzis等人将读取效率提高到$\mathcal{O}\left(\log ^{2 / 3+\varepsilon} N\right)$\cite{IoannisDemertzis2018SearchableEW}。在\cite{IoannisDemertzis2017FastSE}中还提出了$\omega$(1)存储效率的一些权衡。当数据库中最长列表的大小受到限制时，就会得到更好的结果。当需要这样一个上界时，我们将该构造称为有条件的。第一个条件SSE来自于Asharov等人，在最长列表大小为$\mathcal{O}\left(N^{1-1 / \log \log N}\right)$的条件下，达到了O(log log N)的读效率。后来改进为O(log log log N)读效率，但对最长列表的大小的假设变强了，要求为$\mathcal{O}\left(N^{1-1 / \log \log \log N}\right)$。

假设在硬盘存储器上实现时，局部性也被作为内存访问的性能度量而引入。在\cite{AngleBossuat2021SSEAS}中，Bossuat等人表明，在使用固态硬盘(如闪存盘)的情况下，局部性不再是最重要的指标。相反，性能主要取决于访问的内存页的数量，而不是它们是否连续。在这种情况下，更好的性能指标是页面效率。页面效率被定义为服务器为响应查询需要读取的页面数，除以存储明文答案所需的页面数。\cite{AngleBossuat2021SSEAS}的主要结构实现了O(1)存储效率和O(1)页效率，他们假设客户端内存为$\omega$(log $\lambda$)页。

到目前为止，所有现有结构(包括局部结构和页面高效结构)的一个共同点是它们都是纯静态的。这可能是因为构建局部SSE在静态条件下就已经很困难了(从一开始，Cash和Tessaro的不可能性结果就证明了这一点\cite{DavidCash2014TheLO})。然而，SSE的许多应用程序都要求动态性，这一问题严重阻碍了局部高效的SSE的适用性。
\subsection{本文的贡献}
在本文中，我们首次考虑了动态内存高效SSE的问题，并且同时针对动态页面高效SSE和动态局部高效SSE。我们方法的核心是在这两个目标之间建立一种新型的联系。我们引入了一个称为泛型局部变换的映射，它将具有某些特殊特征的高效页SSE方案作为输入，并输出具有强局域性的SSE方案。我们的策略将是首先构建高效页面的方案，然后应用泛型局部变换获得局部版的方案。这种方法被证明是相当有效的，以下是几个结果\ref{table1} \ref{table2}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{table1.png}
  \caption{高效页面SSE方案。N表示数据库的总大小，p是每页元素的数量，$\varepsilon$ > 0是一个任意小的常数，$\lambda$ 是安全参数。页面效率、存储效率和客户端存储效率在章节3.1.2中定义。}
  \label{table1}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.4]{table2.png}
  \caption{局部性SSE方案。N表示数据库的总大小，$\varepsilon$ > 0是一个任意小的常数。局部性、读效率和存储效率的定义见章节3.1.2。}
  \label{table2} %这样，就可以通过~\ref{fig_1}引用图片了
\end{figure}

\begin{itemize}
  \item \textbf{动态高效页面SSE。}我们首先构建一个动态页面高效SSE方案LayeredSSE。LayeredSSE实现存储效率O(1)，页面效率O(log log N)。与之前关于内存高效SSE的工作一致，LayeredSSE的技术核心是一种新的动态分配方案L2C。L2C是所谓的“2-choice”算法的加权变体，在资源分配方面的文献中臭名昭著。因此，L2C部分较为独立。
  \item \textbf{泛型局部变换。}我们将介绍泛型局部变换。在输入任何具有特定特征的页效率方案PE-SSE时，通用局部变换输出一个局部SSE方案Local[PE-SSE]。粗略地说，如果PE-SSE的客户端存储效率O(1)，存储效率O(1)，页面效率O(P)，那么Local[PE-SSE]的存储效率将是O(1)，读取效率O(P)。对于局部性，如果PE-SSE在查询最多一个页面大小的列表时具有局部性O(L)，那么Local[PE-SSE]在查询任何大小的列表时具有局部性O(L + log log N)。因此，从PE-SSE转换为Local[PE-SSE]的过程，可以看作是将具有弱局部性的方案转换到具有强得多的局部性的方案。
  
  我们提出的泛型局部转换还指出了页面效率和局部性这两个指标之间的有趣联系。最初，局部性和页面效率作为不同的性能标准被引入，分别针对两种最广泛的存储介质:硬盘存储器和固态存储器。在\cite{AngleBossuat2021SSEAS}中已经观察到，具有局部性L和读效率R的方案最多具有R + 2L的页效率。从这个意义上说，页面效率是一个“更容易”的目标。令人惊讶的是，使用泛型局部变换时，这个过程反过来了（由难到易了）:我们使用高效页面方案作为基础，转换获得局部版的方案。理论上讲，这显示了两个指标之间的强烈联系。在实际层面上，它提供了同时实现这两个目标的策略。
  \item \textbf{动态局部SSE。}通过将通用局部变换应用于LayeredSSE页效率方案，我们获得了一个动态SSE方案Local[LayeredSSE]，其存储效率O(1)，局域性O(1)，读取效率O(log log N)。这一构造是有条件的:它要求最长列表的大小为$\mathcal{O}\left(N^{1-1 / \log \log N}\right)$。Local[LayeredSSE]的渐近性能与\cite{GiladAsharov2021SearchableSE}的第二个静态结构完全匹配，包括最大列表大小的条件:动态性不需要额外的代价。特别是，Local[LayeredSSE]的性能达到了\cite{GiladAsharov2021TightTI}中SSE方案的下界，对比\cite{GiladAsharov2021TightTI}称为“分配方案”的方案，这表明即使在动态条件下也可以达到理论性能边界。
  \item \textbf{静态设置中无条件的局部SSE。}来自\cite{GiladAsharov2021SearchableSE}的原始1-choice方案无条件地实现O(1)存储效率，O(1)局部性和O(log N)读取效率。在\cite{IoannisDemertzis2018SearchableEW}中，对于任意常数$\varepsilon$ > 0，读取效率提高到$\mathcal{O}\left(\log ^{2 / 3+\varepsilon} N\right)$。这是迄今为止唯一一个无条件实现亚对数效率的SSE方案。通过将泛型局部变换应用于Tethys的变体\cite{AngleBossuat2021SSEAS}，并结合\cite{IoannisDemertzis2018SearchableEW}提出的技术，我们获得了一个无条件静态SSE方案，对于任何常数$\varepsilon$ > 0，它具有存储效率O(1)，局域性O(1)和读取效率$\mathcal{O}\left(\log ^{\varepsilon} N\right)$。据我们所知，这是最接近Cash和Tessaro提出的理论极限的结构(即同时具备O(1)局部性、存储效率和读取效率是不可能的)。
\end{itemize}

\textbf{前向安全性。}本文构建的SSE方案在搜索过程中允许一个标准的“最小”泄漏:泄漏搜索模式和访问模式。对于我们的动态方案，更新操作会泄漏正在更新的列表的标识符，在某些情况下还会泄漏列表的长度。因此，我们的动态方案不是前向安全的。潜在的问题是前向安全性和内存效率的目标似乎从根本上是不一致的。事实上，局部性要求与相同关键字相关联的标识符必须彼此靠近地存储;前向安全则要求插入新标识符的位置应该独立于与其关联的关键字。这个问题已经在\cite{RaphaelBost2016ooFS}中提到了，该文章表示“对于动态方案，局部性和前向隐私是两个不可调和的概念”。可以参考\cite{RaphaelBost2016ooFS}以获得关于该问题的更多讨论，这将是未来的工作。
\section{技术概述}
本文包含几个结果，但由泛型局部转换连接在一起。因此，我们认为将它们放在一篇论文中是有益的。这就需要引入一些不同的分配机制。我们努力在本节中对这些机制作一个清楚的概述。形式化的规范、定理和证明将在后续章节中介绍。

首先回顾一些经过充分研究的分配机制是有帮助的。在接下来的内容中，“具有压倒性的概率”等同于“除了可忽略不计的概率”(在通常的密码学意义上)，而“具有高概率”仅仅意味着在某种意义上概率接近1，但不一定是压倒性的。

\textbf{单选分配(One-choice allocation)。}在单选分配中，n个球被放进n个箱子。每个球被放入一个独立且均匀随机选择的箱子(通过哈希球的标识符)。使用切尔诺夫边界的标准分析表明，在放入过程中，箱子最多包含O(log n)个球，具有高概率\cite{DASprott1978UrnMA}。(对于任意f = $\omega$(1)，绝大多数情况最多有O(f (n) log n)个球。)

\textbf{双选分配(Two-choice allocation)。}同样，n个球被扔进n个箱子。对于每个球，独立且均匀地从两个箱子中随机选择。在放入球的时候，球被放入含有最少球的两个箱子组中。Azar等人的一个著名结果表明，在整个放入过程中，箱子最多包含O(log log n)个球，这一概率很高\cite{YossiAzar1999BalancedA}。(后来证明该结果以压倒性的概率成立\cite{MichaelMitzenmacher2001ThePO}。)

\textbf{布谷鸟哈希。}布谷鸟哈希是由Pagh和Rodler \cite{RasmusPagh2001CuckooH}引入的一种经典哈希方案。在布谷鸟哈希中，n个球被插入到(2 + $\varepsilon$)n个单元中，其中$\varepsilon$ > 0是一个任意小的常数。每个格子最多可以容纳一个球。对于每个球，独立且均匀地从两个单元格中随机选择(例如通过哈希球的标识符)。球被放入两个单元格中的一个。如果该单元已经被占用，则占用的球被移动到其他可能的目标单元(可能会产生连锁反应)。Pagh和Rodler证明了放入的时间期望是O(log n)\cite{RasmusPagh2001CuckooH}(包括在插入失败的情况下，用一个新的哈希函数重建整个表的平摊代价)。最后，类似于双选分配，每个球被存储在两个可能的位置之一。由于更复杂的插入算法(允许移动已经放置的球)，负载最多的单元格(根据定义)的负载为1，而不是O(log log n)的双选分配。

\subsection{分层的双选分配}
我们的第一个目标是构建一个动态页面高效方案。让我们从静态情况开始，总结一下这需要什么。正如在简介中所解释的，要实现单关键字SSE，我们希望在不受信任的服务器上存储任意大小的列表。可以使用对称加密以一种简单的方式来隐藏列表的内容。主要的问题是如何将列表存储在服务器内存中，以这样一种方式访问一个列表不会显示关于其他列表长度的信息。

在页面效率方案的情况下，这个问题可以总结如下。我们有一组列表，总共包含N个项目。我们还得到了一个页面大小p，它表示一个物理内存页面中可以容纳的项的数量。服务器的内存被视为一个页面数组。我们希望将列表存储在服务器内存中，考虑到三个目标指标。

\begin{enumerate}
  \item 为了存储所有列表，我们总共使用S[N/p]页的服务器内存，其中S称为分配方案的存储效率。我们想让S尽可能小。
  \item 任何长度为$\ell$的列表都可以通过访问服务器内存中最多P个[$\ell$/ P个]的页面来检索，其中P称为分配方案的页面效率。我们希望P尽可能小。
  \item 最后，服务器为检索给定列表而访问的页面不应该依赖于其他列表的长度。
\end{enumerate}

前两个目标正是装箱算法的目标。第三个目标是安全目标:它规定服务器执行的内存访问模式不应该泄露某些信息。因此，目标涉及到无关的或数据独立的算法。在\cite{AngleBossuat2021SSEAS}中，实现这三个目标的框架被形式化为数据独立包装(DIP)。

为了便于表示，我们将关注所有列表的大小最多为一页的情况。如果一个列表的长度超过一页，一般的想法是它将被分割成一页的块，加上最后一个最多一页的块;然后，每个块将被分配方案视为一个单独的列表。我们假设从现在开始列表的长度小于一页。

简而言之，\cite{AngleBossuat2021SSEAS}提出的实例化DIP方案的想法是使用布谷鸟哈希的加权变体。更详细地说，对于每个列表，通过散列列表的标识符，统一随机地选择两个页面。然后，列表的每个元素将存储在两个指定页面中的一个页面中，或一个隐藏项中。隐藏项存储在客户端。为了选择每个列表如何在其三个可能的目的地(两个选择的页面，或存储)之间分割，\cite{AngleBossuat2021SSEAS}使用了最大流算法。这个算法的细节与我们的目的无关。重要的一点是，在检索列表时，服务器访问两个统一随机的页面。显然，这不会向服务器透露关于其他列表长度的信息。由此产生的算法，称为Tethys，实现了存储效率O(1)，页面效率$\omega$(1)，客户端存储$\omega$(log $\lambda$)页(用于存储隐藏项)。

在本文中，我们希望建立一个动态SSE。为此，底层分配方案需要允许新的更新操作。更新操作允许客户端向列表中添加一个新项，将其长度增加1。安全性目标本质上与静态情况相同:算法为了更新给定列表而访问的页面不应该依赖于其他列表的长度。

Tethys不适合作为动态方案的基础，因为它不支持有效的与数据无关的更新过程:在更新期间向单元格插入元素时，更新过程需要访问其他单元格，其访问模式本质上是与数据相关的。相反，一个自然的想法是使用双选分配方案的加权变体。使用双选分配，更新期间的访问模式很简单:只需要读取与正在更新的列表关联的两个目标箱子。然后将新项插入到当前包含较少项的两个箱子中。

实现该方法将需要一个双选分配的加权变体，如下所示:给定一个多集列表大小$\left\{\ell_{i}: 1 \leq i \leq k\right\}$，$\ell_{i} \leq p$, $\sum \ell_{i}=N$，在双选分配过程的结果为O(N/p)个箱子时，箱子以压倒性的概率最多包含O(p log log N)个项目。然而，这种形式的结果似乎是一个长期存在的开放问题。据我们所知，所有现有的结果都假设球的权重取样相同且独立于足够平滑的分布。即使不考虑分布上的约束，在我们的问题设置中，我们甚至不能假设列表长度是确定的:在SSE安全模型中，列表是由对手任意选择和更新的。

为了达到我们的目的，我们需要一个无分布的情况:我们只知道每个列表大小的边界p，以及所有列表总大小的边界N。我们需要一个箱子包含项目的上界O(p log log N)，它适用于满足这些约束的任何一组列表大小。这种形式的结果是已知的一种选择分配过程\cite{PetraBerenbrink2005OnWB}(具有O(p log N)上限)，但同一篇文章表明，相同的技术不能扩展到双选过程。

为了解决这一问题，我们引入了一种分层加权二选择分配算法L2C。L2C具有与(加权)二选算法相同的基本行为:对于每个球，均匀随机地选择两个箱子作为可能的目的地。唯一的区别是如何在两个目标箱子中选择实际插入球的箱子。最自然的选择是将球存储在当前负载最小的箱子中，其中箱子的负载是当前所包含的球的权重之和。相反，我们使用一个稍微复杂一点的决策过程。简而言之，我们将球的可能权重划分为O(log log $\lambda$)子区间，并对每个子区间内的球独立执行决策过程。对于第一个子区间(保留最小的权重)，我们使用加权的单选过程，而对于其他子区间，我们使用未加权的双选过程。

这种结构的要点在于，它的分析可以简化为加权的单选过程和非加权的双选过程的分析，这双选过程以强大的分析技术而闻名。我们利用这些技术来证明L2C在负载最多的箱子的负载上实现了所需的无分布情况。在实践中，这意味着我们有一个分配算法，在大多数情况下，表现得像双选分配的加权变体，并且可以相对容易获得无分布条件。多选分配过程在计算机科学的某些领域普遍存在，因此它相对独立，本文不表。

LayeredSSE方案是通过在L2C之上增加一层加密和密钥管理，使用SSE文献中的标准技术来实现的。详情请参阅第5.2节。


\subsection{泛型局部变换}
在Crypto 2018上，Asharov等人确定了构建局部SSE的两个主要范例\cite{GiladAsharov2021TightTI}。第一个是分配范式，它通常使用多选分配方案的变体，或布谷鸟哈希法。第二种是填充和分割方法。高效内存SSE的主要困难在于将不同大小的列表打包在一起。填充和分割方法的思想是根据列表的大小分别存储列表，从而避免了这个问题。实现这一点最简单的方法是填充所有列表的长度到下一个2的幂。这将产生log N个列表长度的可能值。所有给定长度的列表都可以存储在一起，例如，使用标准哈希表。由于我们不想透露每种长度的列表的数量，因此每一层的哈希表都需要进行维数划分，以便能够接收整个数据库。因此，基本的填充和分割方案的存储效率为O(log N)，但很容易实现O(1)局部性和读取效率。

对于泛型局部变换，我们引入了溢出SSE (OSSE)的概念。OSSE在所有方面都像SSE方案，除了在其设置和更新期间，它可能拒绝存储一些列表元素。这样的元素称为溢出。OSSE打算用作overaching SSE构造中的子组件。OSSE方案用于存储部分数据库，而溢出元素则使用单独的机制存储。OSSE的概念之前并没有形式化，但事后看来，OSSE的使用可能被视为隐含在几个现有的结构中。为了便于阐述，我们选择在这里显式地介绍它。

现在我们来解释泛型局部变换。填充和分割方法的主要限制是它在存储中创建了log N的开销。因此，泛型局部变换的高级思想是使用OSSE存储数据库中除1/ log N以外的所有数据。然后使用“填充-拆分”变体存储N/ log N个溢出元素。这样做的目的是受益于填充和分割方法的高效率，而不必支付log N的存储开销

然而，这种方法有一个微妙但重要的问题。给定的列表可以完全存储在OSSE方案中，或者只存储部分，或者根本不存储。在我们稍后将使用的OSSE方案(以及之前工作中隐含的OSSE)中，服务器应该无法区分这三种情况，否则安全性无法保证。为了解决这个问题，我们采取如下措施。

让我们假设所有的列表都被填充到下一个2的幂。对于构造的填充和分割部分，我们创建了log N个SSE实例，每个实例对应一个可能的列表大小。我们将每个实例称为一个层。如果一个列表的大小为$\ell$，它的溢出元素将存储在处理大小为$\ell$的列表的层中，而不管有多少元素从该列表的OSSE溢出。

OSSE提供的关于溢出元素的唯一保证是它们的总数不等于O(N/ log N)。因此，如果我们关注处理大小为$\ell$的列表的层，该层将接收最多的元素。这些元素将被分割成大小不超过$\ell$的列表(对应于溢出元素的集合，对于原始数据库中大小为$\ell$的每个列表)。为了实现整体存储效率O(S)，我们希望该层使用O(Sn)存储来存储这些列表。为了实现读效率R，该层还应该能够通过访问最多R$\ell$内存位置来检索给定的列表。满足这些条件的SSE方案正是页面大小为$\ell$、存储效率为S、页面效率为R的高效页面SSE方案。

每一层使用的页面高效方案还需要满足一些额外的属性:首先，当搜索最多一页的列表时，列表的长度不应该泄露。我们称之为propertype-length-hiding。所有现有的高效页结构都具有该属性。其次，我们要求页面高效方案拥有O(1)的客户端存储效率。本文中的所有结构都满足这个性质，但\cite{AngleBossuat2021SSEAS}中的结构不满足。最后，我们要求该方案在获取单个页面时具有O(1)的局部性。所有现有的高效页结构都具有此属性。(最后两个属性可以放宽，但要付出更复杂的公式和语句的代价。)我们称满足这三个性质的SSE方案为合适的。

将所有内容放在一起，通用局部转换将一个合适的页效率方案作为输入，存储效率S和页效率P。它输出一个存储效率S + S '，读取效率P + R '和局部性L '的局部方案，其中S '， R '和L '是底层OSSE的存储效率，读取效率和局部性。接下来还需要解释如何构建具有O(N/ log N)个溢出项的局部OSSE方案。

\subsection{ClipOSSE: O(N/ log N)个溢出项的OSSE方案}
在2016年STOC上，Asharov等人引入了所谓的“二维”版本的单选和双选分配，目的是建立局部SSE。单选变体的工作原理如下。考虑一个有N个元素的SSE数据库。分配m = O (N/ log N)个箱子，初始为空。对于数据库中每个长度为$\ell$的列表，随机统一选择一个箱子。列表的第一个元素被插入到该箱子中。列表的第二个元素被插入到下一个箱子中(假设箱子的顺序是固定的，当到达最后一个箱子时，顺序会改变)，第三个元素被插入到之后的箱子中，依此类推，直到所有列表元素都被插入。因此，假设$\ell$<=m，所有列表元素都被放置在$\ell$连续的箱子中，每个箱子中有一个元素。分析表明，在压倒性的概率下，箱子最多拥有$\tau$ =′O (log N)个元素。为了从这个分配方案构建一个静态SSE方案，每个箱子都被填充到最大大小$\tau$并加密。搜索请求以自然的方式进行。

这样的方案具备存储效率O(1)、局部性O(1)(因为检索列表相当于读取连续的箱子)和读取效率O(log N)(因为检索长度为$\ell$的列表需要读取$\ell$个箱子，每个箱子的大小$\tau$ = O(log N))。为了构建ClipOSSE，我们从相同的前提开始，但是在阈值$\tau$ =′O (log log N)处“截取”箱子。也就是说，每个箱子最多只能放入$\tau$个元素。无法放入的元素被溢出。

在标准的单选过程中，将n个球i.i.d.扔到n个箱子中，不难证明在高度$\tau$ = O(log log n)处剪切箱子会以压倒性的概率导致最多O(n/ log n)个溢出元素。事实上，通过在$\tau$的选择中调整乘法常数，对于任何给定的常数d，溢出元素的数量可以变成$\mathcal{O}\left(n / \log ^{d} n\right)$。我们表明，这种形式的结果仍然适用于前面概述的二维一选过程(一种近似的变体)。结果是有条件的:它要求最大列表大小为O(N/polylog N)。(这种形式的条件是必要的，因为当最大列表大小接近N/ log N时，结果会失败。)相应定理的证明是这项工作中最具技术挑战性的部分，它依赖于凸性论证和随机支配性论证的结合。

最后，在最大列表大小为O(N/polylog N)的条件下，ClipOSSE实现了存储效率O(1)，局域性O(1)和读取效率O(log log N)，有O(N/ logd N)个溢出元素(对于我们选择的任何固定常数d)。本文中通用局部转换的所有应用程序都使用ecliposse作为底层OSSE。

\subsection{开销为O(log log N)的动态局部SSE}
通过使用ClipOSSE作为底层OSSE, LayeredSSE作为页面高效方案的泛型局部变换，我们得到了Local[LayeredSSE]。Local[LayeredSSE]方案的存储效率为O(1)，局域性为O(1)，读取效率为O(log log N)。这个结果来自于关于泛型局部变换的主要定理，不需要任何新的分析。

Local[LayeredSSE]是一个带条件的方案:它要求最长列表的长度为$\mathcal{O}\left(N^{1-1 / \log \log \lambda}\right)$。ClipOSSE本身有一个条件，即最长的列表是O(N/polylog N)，这个条件要求较低。这种情况的原因归结为LayeredSSE只有在方案中的页面数至少为$\Omega\left(\lambda^{1 / \log \log \lambda}\right)$的情况下才能实现可以忽略不计的失败概率。

\subsection{无条件静态局部SSE，开销$\mathcal{O}\left(\log ^{\varepsilon} N\right)$}
来自\cite{AngleBossuat2021SSEAS}的静态Tethys方案同时实现了存储效率O(1)和页面效率O(1)。它也能隐藏页面长度的。由于我们可以使用通用局部变换，因此很容易将其应用于Tethys。然而，有一个障碍:Tethys使用$\omega$(p log $\lambda$)客户端内存，以便在客户端存储一个隐藏项。对于泛型局部变换，我们需要O(1)个客户端内存。为了减少Tethys的客户端内存，一个简单的想法是将隐藏项存储在服务器端。简单地说，每次搜索都读取隐藏项会将页面效率提高到$\omega$(log $\lambda$)。为了避免这种情况，我们将隐藏文件存储在ORAM中。

为此，我们需要一个失败概率为零的ORAM:实际上，由于我们可以在ORAM中存储最少log $\lambda$个元素，因此，negl(n)的正确性保证(其中n = log $\lambda$是ORAM中项目的数量)是不够的(它不是negl($\lambda$))。我们还需要ORAM具有O(1)局部性。基于同样的问题，\cite{IoannisDemertzis2018SearchableEW}设计了具有这些特征的ORAM。来自\cite{IoannisDemertzis2018SearchableEW}的ORAM对于任意常数$\varepsilon$ > 0的读取效率为$\mathcal{O}\left(n^{1 / 3+\varepsilon}\right)$。在\cite{IoannisDemertzis2018SearchableEW}中已经推测可以改进到$\mathcal{O}\left(n^{\varepsilon}\right)$。我们显式地构建该变体，并将其命名为itLocORAM。粗略地说，LocORAM是Goldreich-Ostrovsky分层ORAM的变体，具有恒定数量的级别。

通过将Tethys的存储放在服务器端的LocORAM中，我们自然而然地获得了一个页面高效的SSE方案OramTethys，具有$\mathcal{O}\left(\log ^{\varepsilon} \lambda\right)$读取效率，适合在通用局部转换中使用。对于大小不超过N/polylog N的列表，生成一个静态局部SSE。为了处理更大的列表，借鉴了\cite{IoannisDemertzis2018SearchableEW}的一些想法，我们根据大小对列表进行分组，并再次使用OramTethys来存储它们。最后，我们得到了一个具有O(1)存储效率、O(1)局部性和$\mathcal{O}\left(\log ^{\varepsilon} \lambda\right)$读取效率的无条件SSE

与\cite{IoannisDemertzis2018SearchableEW}的$\mathcal{O}\left(\log ^{2 / 3+\varepsilon} \lambda\right)$结构相比，我们注意到其结构的瓶颈来自作者用于他们所谓的“小”和“中”列表的分配方案。这正是我们使用Local[OramTethys]的范围。我们的结构基本上消除了这个瓶颈，因此$\mathcal{O}\left(\log ^{\varepsilon} \lambda\right)$读取效率瓶颈现在完全来自ORAM组件。
\section{准备工作}
设$\lambda \in \mathbb{N}$为安全参数。对于概率分布X，我们用$x \leftarrow X$表示从分布中采样值X的过程。此外，用$[a, b]_{\mathbb{R}}$表示区间$\{x \in \mathbb{R} \mid a \leq x \leq b\}$，并将其自然地扩展到$[a, b)_{\mathbb{R}},(a, b]_{\mathbb{R}},(a, b)_{\mathbb{R}}$形式的区间。
\subsection{对称可搜索加密}
数据库$\mathrm{DB}=\left\{w_{i},\left(\mathrm{id}_{1}, \ldots, \mathrm{id}_{\ell_{i}}\right)\right\}_{i=1}^{W}$是具有W个关键字的关键字标识符对的集合。我们假设每个关键字Wi由O（$\lambda$）位的机器字表示。$\mathrm{DB}\left(w_{i}\right)=\left(\mathrm{id}_{1}, \ldots, \mathrm{id}_{\ell_{i}}\right)$用于匹配Wi的标识符列表。设$N=\sum_{i=1}^{W} \ell_{i}$在本文中，我们将p定义为页面大小，并将p视为变量，与数据库N的大小无关。

动态可搜索对称加密方案是PPT算法（KeyGen、Setup、Search、Update）的4元组，使得

\begin{itemize}
  \item $\Sigma{KeyGen}\left(1^{\lambda}\right)$：将安全参数$\lambda$作为输入，并输出客户端密钥K。
  \item $\Sigma { Setup }(\mathrm{K}, N, \mathrm{DB})$：将客户端密钥K、数据库大小N的上限和数据库DB作为输入。输出加密数据库EDB和客户端状态st。
  \item $\Sigma{Search}(\mathrm{K}, w, \mathrm{st} ; \mathrm{EDB})$：客户端接收密钥K、关键字w和状态st作为输入。服务器接收加密数据库EDB作为输入。为客户端输出一些数据d和更新的状态st′。为服务器输出更新的加密数据库EDB′。
  \item $\Sigma { Update }\left(\mathrm{K},\left(w, L^{\prime}\right), { op, st; EDB }\right)$：客户端接收密钥K、一对（w，L）关键字w和标识符列表L′、操作${ op } \in{  [del, add] }$和状态st作为输入。服务器接收加密数据库EDB′作为输入。输出客户端的更新状态st′。为服务器输出更新的加密数据库EDB′
\end{itemize}

在下文中，我们省略了状态st，并假设它由客户端隐式存储和更新。我们说$\sum$是静态的，如果它不提供更新算法。此外，我们假设每当客户端在Search或Update中向服务器发送w时，客户端都会通过PRF对关键字w进行预处理。这确保了服务器永远无法访问明文中的w，并且未经排序的关键字在服务器的视图中均匀随机分布。

直观地说，客户端使用$\sum$.Setup加密并将数据库DB外包给服务器。然后，客户端可以使用$\sum$搜索关键字w，并从服务器接收匹配的标识符DB（w）。匹配标识符的列表也可以使用$\sum$.Update进行更新，前提是数据库的大小保持在N以下。

\subsubsection{安全性}
我们现在定义SSE的正确性和语义安全性。直观地说，正确性保证了搜索总是检索所有匹配的标识符，语义安全保证了服务器只从客户端学习有限的信息（通过泄漏函数量化）。

\textbf{定义3.1（正确性）。}如果对于数据库DB, $N \in \mathbb{N}$，$K\leftarrow\Sigma {KeyGen}\left(1^{\lambda}\right), \mathrm{EDB} \leftarrow \Sigma {Setup}(\mathrm{K}, \mathrm{DB})$，设（K，DB）和搜索序列，添加或删除请求序列S，如果数据库的大小保持最多N，搜索协议为序列的所有查询返回正确的结果，则满足正确性。

我们使用SSE的标准语义安全概念。安全性由泄漏函数$\mathcal{L}=\left(\mathcal{L}_{{Stp }}, \mathcal{L}_{{Srch }}, \mathcal{L}_{{Updt }}\right)$参数化，泄漏函数由设置泄漏$\mathcal{L}_{{Stp }}$、搜索泄漏$\mathcal{L}_{{Srch }}$和更新泄漏$\mathcal{L}_{{Updt }}$组成。我们定义了两种场景，SSEReal和SSEIdeal。首先，对手选择数据库DB。在SSEReal中，加密数据库EDB由Setup（K，N，DB）生成，而在SSEIdeal中，加密的数据库由输入$\mathcal{L}_{{Stp }}$（DB，N）上的（有状态）模拟器Sim模拟。收到EDB后，对手发出搜索和更新请求。在SSEReal中诚实地回答所有问题。在SSEIdeal中，Sim在输入$\mathcal{L}_{{Srch }}$（w）上模拟对关键字w的搜索请求，并且Sim在输出$\mathcal{L}_{{Updt }}$（op，w，L′）上模拟操作op、关键字w和标识符列表L′的更新请求。最后，对手输出b位。

如果对手的查询是自适应选择的，即取决于先前的查询，我们将编写SSERealadp和SSEIdealadp。类似地，如果对手有选择地选择查询，即在接收EDB之前与数据库一起初始发送，则我们编写SSERealsel和SSEIdealsel。

\textbf{定义3.2（语义安全）。}设$\sum$为SSE方案，$\mathcal{L}=\left(\mathcal{L}_{{Stp }}, \mathcal{L}_{{Srch }}, \mathcal{L}_{{Updt }}\right)$为泄漏函数。如果对于所有PPT对手A，存在PPT模拟器Sim，则方案$\sum$是L-自适应安全的

$\left|{Pr}\left[{SSEREAL}_{\Sigma, \mathcal{A}}^{\mathrm{adp}}(\lambda)=1\right]-{Pr}\left[{SSEIDEAL}_{\Sigma, {Sim}, \mathcal{L}, \mathcal{A}}^{\mathrm{adp}}(\lambda)=1\right]\right|={neg} \mid(\lambda)$

类似地，如果对于所有PPT对手A，存在PPT模拟器Sim，则方案$\sum$是L-选择性安全的

$\left|{Pr}\left[{SSEREAL} \sum_{\Sigma, \mathcal{A}}^{ {sel }}(\lambda)=1\right]-{Pr}\left[{SSEIDEAL} \sum_{\Sigma, {Sim}, \mathcal{L}, \mathcal{A}}^{ {sel }}(\lambda)=1\right]\right|={neg} \mid(\lambda)$

直观地说，语义安全保证了客户端和服务器之间的交互不会向服务器透露任何信息，除了给定查询的泄漏。本文中的方案具有常见的泄漏模式。我们使用\cite{RaphaelBost2016ooFS}中的查询模式qp和历史Hist的标准概念来形式化该泄漏。（1） 关键字w的查询模式qp（w）是关键字w的先前搜索或更新请求的索引（3） 历史Hist（w）由匹配在设置期间插入的关键字w的标识符列表和关键字w的更新历史组成，即每个删除和插入的标识符。我们可以检索数字$\ell$i和从Hist（w）中删除的标识符的数量di。

\subsubsection{效率优化}

我们回顾了局部性、存储效率和读取效率\cite{DavidCash2014TheLO}以及页面效率\cite{AngleBossuat2021SSEAS}的概念。此外，我们以自然的方式扩展了它们的动态方案。在以下定义中，设$K\leftarrow\Sigma {KeyGen}\left(1^{\lambda}\right), \mathrm{EDB} \leftarrow \Sigma {Setup}(\mathrm{K}, \mathrm{DB})$, 设文档标识符数量的上限N，S=是一个搜索和更新请求序列，其中op是一个操作，in是其输入，Wi是一个关键字，L′i是标识符列表，在执行所有之前的操作op之后，st是客户端状态，EDB是加密数据库。我们用DBi表示i次操作后的数据库。我们假设标识符的总数永远不会超过N。

\textbf{定义3.3（读取模式）。}将服务器端存储视为包含加密数据库EDB的内存位置数组。处理搜索请求search或更新请求update时，称为读取模式，并用RdPat（op，in）表示。

\textbf{定义3.4（局部性）。}SSE方案具有局部性L，如果对于任何$\lambda$、DB、N、序列S和任何i，RdPat（opi，ini）由至多L个不相交间隔组成，则称为具备局域性。

\textbf{定义3.5（读取效率）}。如果对于任何$\lambda$、DB、N、序列S和任何i，SSE方案具有读取效率R，$\left|{RdPat}\left(\mathrm{op}_{i}, \mathrm{in}_{i}\right)\right| \leq R \cdot P$其中P是存储所有（添加和删除的）与明文中的关键字wi匹配的文档索引（通过连接索引）所需的存储位置数。

\textbf{定义3.6（存储效率）。}如果对于任何$\lambda$、DB、N、S和任何i，|EDBi|<=E·|DBi|，SSE方案具有存储效率E。

同样，我们现在定义页面效率。此效率度量以存储介质SSD为目标。

\textbf{定义3.7（页面模式）。}将服务器端存储视为包含加密数据库EDB的页面数组。处理搜索请求search或更新请求update，读取模式RdPat（op，in）引起多个页面访问p1...ph′。我们称这些页面为页面模式，由PgPat（opi，ini）表示。

\textbf{定义3.8（页面成本）。}SSE方案具有页面成本aX+b，其中a、b是实数，X是固定符号，如果对于任何$\lambda$、DB、N、序列S和任何i，|PgPat（opi，ini）|<=aX+b，其中X是以明文存储匹配关键字wi的文档索引所需的页面数。

\textbf{定义3.9（页面效率）。}如果对于任何$\lambda$、DB、N、S和任何i，|PgPat（$\tau$，EDB）|<=P·X，SSE方案具有页面效率P，其中X是在明文中存储匹配关键字wi的文档索引所需的页面数量。

\section{L2C}
在本节中，我们描述了我们的算法L2C，它允许将n个加权球分配到m个箱子中，其中每个球bi的权重wi$\in$[0,1]。首先，设1<=$\delta$($\lambda$)<=log($\lambda$)为函数。我们用w =$\sum$n i=1表示所有权重的总和，并设m = w/($\delta$($\lambda$) log log w)。我们稍后将选择$\delta$($\lambda$) = o(log log $\lambda$)，以便稍后分配的失败概率可以忽略不计。在概述中，我们设$\delta$($\lambda$) = 1，并为简单起见假设m = $\omega$($\lambda$)(这足以忽略故障概率)。

\subsection{L2C概述}
L2C是基于未加权的单选分配(1C)和未加权的双选分配(2C)。在高层次上，我们把可能的权重[0,1]分成log log m个子区间

$[0,1 / \log m]_{\mathbb{R}},(1 / \log m, 2 / \log m]_{\mathbb{R}}, \ldots,\left(2^{\log \log m-1} / \log m, 1\right]_{\mathbb{R}}$


换句话说，第一个区间的大小为1/ log m，区间之间的边界每次增长2倍。我们将在给定的子区间内独立于其他子区间分配权重的球。

第一个子区间中的球的权值wi<=log m，因此小到可以应用1C。直观地说，这就足够了，因为对于最大大小为1/logm的均匀权重，单项选择的性能最差。最多有n ' = w log m个球，我们期望一个箱子包含n ' /m = log m·log log w个权重均匀的球，因为m = w/(log log w)。由于每个球的权重为1/ log m，每个箱子的期望负载为log log w。在应用切尔诺夫边界后，这转化为O(log log w)的压倒性概率。


对于其他区间，每个区间应用未加权且独立的2C就足够了，因为球的权重最多相差一个因子2，并且只有loglogm个区间。更具体地说，设ni为第i个子区间$A_i=\left(2^{i-1} / \log m, 2^i / \log m\right]_{\mathbb{R}}$中的球的个数，其中i$\in$[1，…， log log m]。权重在子区间Ai中的球填充箱子最多为O(ni/m + log log m)个球，与其他子区间无关。请注意，我们使用的是小权重，因此可能有$\omega$(m)球。因此，对于重载情况，我们需要将现有的2C结果扩展到m中可忽略的失效概率(参见引理11)。由于只有log log m个子区间，而区间Ai中的球的权重不超过2i/ log m，我们可以将每个子区间的载荷相加，得到一个上界。

$\sum_{i=1}^{\log \log m} \frac{2^i}{\log m} \mathcal{O}\left(n_i / m+\log \log m\right)=\mathcal{O}(w / m+\log \log m)$

总的来说，对于第一个区间和其余区间，我们有O(w/m + log log m) = O(log log m)边界。总的来说，这表明在分配所有n个物品后，所有箱子的负载最多为O(log log m)。如果m = $\omega$($\lambda$)，这与未加权球的标准2C的边界相匹配。对于我们的SSE应用程序，我们希望允许可以忽略不计的失败概率和尽可能少的箱子数量。我们可以设置$\delta$($\lambda$) = log log log($\lambda$)，如果m = w$\delta$($\lambda$) log log w，我们可以以压倒性的概率获得一个大小为O (log log w)的箱子。这种情况下的分析是相同的。

\textbf{处理update。}本文所描述的L2C变体是静态的。也就是说，如果我们添加球或更新球的权重，我们没有显示加载最多的箱子的负载的边界。幸运的是，上面的分析可以简单地覆盖新球的加入情况，如果m最初被选得足够大，就能补偿增加的权重。因此，我们假设添加的球的总权重有一个上限wmax，用于最初设置箱子。谨慎起见，我们还可以更新权重。

为此，设bi是一个有权重的球。我们想更新它的权重为wnew > wold。如果wold和wnew都在子区间内，我们可以直接更新bi的权重，因为L2C在选择箱子时忽略了给定子区间内球的具体权重。实际上，在第一个区间中，插入bi的箱子是由单个随机选择决定的，对于其余的子区间，2C过程只考虑同一子区间内的球的数量，忽略具体的权重。

当wnew大于当前子间隔的边界时，我们需要确保将球插入到它所选择的两个正确的箱子中。为此，将球bi插入到新子区间内具有权重的球数量最少的箱子中。即使在这个过程中bi的箱子可能会发生变化，我们仍然需要将bi视为旧箱子中的一个权重球，以便后续在旧子区间中插入球。因此，我们将球标记为剩余球，但不将其从旧的箱子中移除。也就是说，我们认为它是2C过程的权重球，但假设它不再被bi标识。由于只有log log m个不同的子区间，剩余球的开销只有常数。完整的算法在算法1中给出。我们将其参数化为一个哈希函数H，统一映射为[1，…, m] 2.由$\alpha$1， $\alpha$2$\leftarrow$H(bi)给出球bi的随机仓值。

\subsection{L2C负载分析}
设$\delta$($\lambda$) = 1或$\delta$($\lambda$) = loglog$\lambda$且m足够大，使得m−$\omega$($\delta$($\lambda$) loglogw) = negl($\lambda$)。(注意，这是1C和2C分配失败的概率。)

我们需要证明，在设置后和在(选择性)操作序列中，加载最多的仓的负载最多为O($\delta$($\lambda$) log log wmax)，其中wmax是插入球的总权重的上限。我们在这里简述证明，并参考附录B获得进一步的细节。首先，我们修改序列，这样我们可以将分析减少到只有(充分独立的)L2C。InsertBall操作，而只增加一个常数因子的最终箱子负载。这是恒定因素的负荷是由于额外的权重残余球。然后，我们分别分析了每个子区间加载最多的箱子的负载。这可以归结为对第一个子区间中的1C流程的分析，以及L2C概述中的其余子区间中的2C流程的分析。把这些独立的边界加起来就可以得到想要的结果。

\textbf{定理1。}令$\delta$($\lambda$) = 1或$\delta$($\lambda$) = loglog$\lambda$。令wmax = poly($\lambda$) m = wmax/($\delta$($\lambda$) log log wmax)。我们要求m = $\omega$($\lambda$ 1log log $\lambda$)如果$\delta$($\lambda$) = log log log $\lambda$或m = $\omega$($\lambda$)。设{(bi, wi)n i=1}是具有(成对唯一)标识bi和权重wi$\in$[0,1]的球。进一步，设S = (opi, ini) S +n i=n+1为S个插入或更新操作序列opi$\in${L2C。InsertBall L2C。UpdateBall}输入ini = (bi, wi, B$\alpha$i,1, B$\alpha$i,2)用于插入，ini = (bi, oi, wi, B$\alpha$i,1, B$\alpha$i,2)用于更新。这里，bi表示在执行opi之前，权重为wii的球的标识符，旧权重oi<=wi。同时，通过$\alpha$i,1， $\alpha$i,2$\leftarrow$H(bi)来选择箱子。

执行(Bi)=1$\leftarrow$L2C。设({(bi, wi)n i=1})，对所有i$\in$[n + 1, n + s]的操作opi(in)。我们要求$\sum$n+s i=1 wi - oi<=wmax，即所有操作后的总权值不超过wmax。

则在整个过程中，所有箱子的的最大负载为O($\delta$($\lambda$) log log wmax)。
\section{动态页面高效SSE}
本节介绍基于L2C的SSE方案LayeredSSE。从本质上讲，我们将匹配关键字wi的标识符列表Li解释为具有一定权重的球，并使用L2C来管理m个箱子中的球。让n是数据库的最大大小，p是页面大小，H是映射到[1，…， m]2 对于 m =[wmax/(log log log $\lambda$·log log wmax)]，wmax = N/p。假设|Li|<=p，即每个关键字最多有p个关联关键字。

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{table3.png}
  % \caption{}
  \label{table3}
\end{figure}

\begin{itemize}
  \item L2C.Setup $\left(\left\{\left(w_i, L_i\right)\right\}_{i=1}^W, w_{\max }\right)$:我们将对(wi, Li)解释为一个具有标识符wi和权重|Li|/p$\in$[0,1]的球，其中Li是匹配关键字wi的(最多p个)标识符的列表。(wi, Li)的箱子选项由a1， a2$\leftarrow$H(wi)给出, 运行算法1中定义的设置。
  \item L2C.InsertBall $\left((w, L), B_{\alpha_1}, B_{\alpha_2}\right)$:将球(w, L)插入到箱子 Ba1或箱子 Ba2中，如算法1所示。
  \item L2C. Update $\left((w, L), L^{\prime}, B_{\alpha_1}, B_{\alpha_2}\right)$:将球(w, L)的权重更新为算法1中的权重，并在列表L中增加标识符L '。如果新的权重位于不同的子区间，则一个箱子包含一个我们认为不再匹配的剩余球(w, L)。
\end{itemize}

\subsection{分层SSE}
在此，我们描述了基于l2c的动态页面高效对称可搜索加密方案LayeredSSE。为了简要概述，我们假设$\ell$i<=p，现在忽略删除操作。此外，我们还提供了一个需要2个rtt的更新版本的方案。稍后，我们将展示如何处理任意大小的列表，引入删除操作，并展示如何在1个RTT中获取更新。

LayeredSSE.KeyGen(1$\lambda$)。给定安全参数$\lambda$， Enc的加密密钥样本KEnc。返回客户端的主密钥K = KEnc。

LayeredSSE.Setup(K, N, DB)。接收客户端的密钥K作为输入，标识符数量的上限N和初始数据库DB = (DB(wi))W i=1。DB(wi) = (id1，…， id$\ell$i)是$\ell$i个文档标识符的列表，$\sum$W i=1$\ell$i<=N。将(wi, DB(wi))解释为一个权重球$\ell$i/p$\in$[0,1]，并调用L2C。设置最大权重N/p和球(wi, DB(wi))W i=1作为输入。L2C中的两个随机选项($\alpha$i,1， $\alpha$i,2)$\leftarrow$H(wi)。通过计算wi上的H来绘制Setup。结果是m个箱子(Bi)m i=1，装满了球，使得每个箱子最多装载c log log log($\lambda$) log log log(N/p)(见定理1)。因此，每个箱子最多包含p·c log log log log($\lambda$) log log log(N/p)标识符，因为权重被一个因子p扩展。(常数tc$\in$N只取决于N，而不取决于L2C.Setup的输出。)接下来，每个箱子都装满了最大大小的球。最后加密箱子 Benci$\leftarrow$EncKEnc (Bi)，返回EDB = (Benci)m i=1。

LayeredSSE.Search(K, w;EDB)。客户端收到密钥K和关键字w。将w发送给服务器，并返回到箱子 Benc$\alpha$1, Benc$\alpha$2，其中($\alpha$1， $\alpha$2)$\leftarrow$H(w)。

LayeredSSE.Update(K， (w, L ')，添加;EDB)。客户端接收到密钥K，关键字w和匹配w的新标识符列表L '。将w发送给服务器，并再次接收到箱子 Benc$\alpha$1, Benc$\alpha$2，其中($\alpha$1， $\alpha$2)$\leftarrow$H(w)。接下来，客户端将Benc$\alpha$1, Benc$\alpha$2解密为B$\alpha$1, B$\alpha$2，并从对应的箱子 B$\alpha$$\in${B$\alpha$1, B$\alpha$2}中检索球(w, L)。然后，调用L2C。更新球，使用旧的球(w, L)，新的标识符L '和箱子B$\alpha$1, B$\alpha$2插入新的标识符L '到B$\alpha$。最后，重新加密箱子并将它们发送到服务器。然后，服务器用更新的箱子替换旧的箱子。

\subsection{安全性}
LayeredSSE方案是正确的，因为每个关键字都有两个包含与其相关联的标识符的箱子(并且这些箱子始终使用L2C检索和更新)。如果将哈希函数建模为随机oracle，则箱子选择是均匀随机的，并且定理1保证箱子不会溢出。

此外，LayeredSSE是选择性安全的，并具有标准设置泄漏N，例如搜索和更新泄漏qp，其中qp是查询模式5。这可以用一个简单的混合参数来表示。对于Setup，模拟器Sim接收N，重新计算并初始化m个空箱子B1，…， Bm的大小p·c log log log($\lambda$) log log log(N/p)。然后Sim outputsEDB ' = (EncK ' enc (Bi)m i=1)为一些采样键K ' enc。由于Enc是IND-CPA安全的(在真实实验中，除了可以忽略不计的概率外，箱子不会溢出)，因此输出EDB '与真实实验中Setup的输出没有区别。对于关键字w的搜索请求，Sim检查查询模式nqp是否已经查询了w。如果之前没有查询w, Sim一个新的统一随机关键字w '。否则，Sim将使用与前一个查询相同的关键字w '响应。因为我们假设关键字是由客户端通过PRF进行预处理的，所以关键字w和w '是不可区分的。对于关键字w的更新请求，第一个流中的客户端输出与搜索请求中的相同，因此Sim可以像在搜索中一样进行。对于第二个流程，Sim从对手处接收到两个箱子 B$\alpha$1, B$\alpha$2，直接重新加密并发送回对手。这种行为是不可区分的，因为箱子是加密的，而且箱子不会溢出，除非概率可以忽略不计。

对于自适应安全性，对手可以根据以前的查询发出搜索和更新请求。因为定理1假设有选择地选择InsertBall和UpdateBall操作，所以不能保证箱子在真正的游戏中不要再溢出。因此，如果对手设法在真实游戏中溢出一个箱子，就可以潜在地将模拟游戏的更新请求与真实的更新请求区分开来，因为它只有在真实游戏中才会收到增加大小的箱子。幸运的是，我们可以在update中添加一个检查，检查是否有一个箱子在L2C之后溢出。UpdateBall操作。在这种情况下，客户端将恢复更新并发回(重新加密的)原始数据箱。现在，定理1仍然保证在设置之后，箱子溢出的概率可以忽略不计，我们可以证明模拟游戏与之前的真实游戏没有区别。(注意，LayeredSSE在这个修改后仍然是正确的，因为查询是选择性地选择正确性。)请注意，在现实环境中，当客户端指出在更新中箱子溢出时，这是由于恶意更新操作造成的。客户端可以相应地调整自己的反应，而服务器在没有客户端通知的情况下不会了解有关攻击的信息。
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{table4.png}
  % \caption{}
  \label{table4}
\end{figure}
结果表明，调整了Update后的LayeredSSE是正确的和自适应安全的。同样的模拟Sim就足够了，这里省略了细节。

\subsection{扩展}
\subsubsection{处理长列表}
我们现在调整LayeredSSE来处理任意列表L(可能有超过p个标识符)。(我们类似于\cite{AngleBossuat2021SSEAS}的静态方案Pluto，并将想法扩展到更新中。)对于这个，我们把L分开(加密的)大小为p的完整子列表可以存储在服务器上的一个哈希表Tfull中，不完整的子列表由LayeredSSE像以前一样处理。对于搜索，客户端需要知道子列表的数量，以便从服务器获取正确的数量。更新请求也需要此信息，以便知道何时将另一个完整列表插入Tfull。这些信息可以外包到表Tlen中。在这里，客户端为每个关键字w(带有$\ell$匹配标识符)以加密格式存储sublistsTlen[w] =[$\ell$/p]的数量。下面，我们将详细介绍flayeredsse的更新设置、搜索和更新。

设置。对于设置，设Li是匹配关键字wi的$\ell$i标识符的列表，PRF是映射到{0,1}[log(N)]的安全伪随机函数。设xi =[$\ell$i/p]。客户端将Li拆分为子列表Li,1，…它计算mi$\leftarrow$PRFKPRF (wi)，其中KPRF是KeyGen中采样的prf的一个键。掩码mi用于加密Tlen的内容。在初始化表Tlen和表Tfull后，Tlen[wi] = xi⊕mi和Tfull[w || i] = Li,j for j$\in$[1,x−1]。接下来，它用不完整列表Li,xi生成(Bi)m i=1，除了列表Li,xi的箱子选项是($\alpha$i,1， $\alpha$i,2)$\leftarrow$H(wi || xi).(这是因为在一些更新之后，wi的不完整子列表可能会满，必须启动一个新的不完整子列表。)当新的不完整子列表插入L2C时，它被解释为一个新的球，需要选择新的箱子。)最后，它加密Tfull的内容并返回EDB = (Tlen, Tfull， (Benci)m i=1)。

搜索。对于关键字w的搜索请求，客户端输出掩码m$\leftarrow$PRFKPRF (w)，服务器使用此掩码解密子列表的数量x$\leftarrow$Tlen[w]⊕m，从表i$\in$[1,x−1]中获取x−1加密的sublistsLi$\leftarrow$Tfull[w || i]，并通过($\alpha$1， $\alpha$2)$\leftarrow$H(w || x)获取两个箱子 (Benc$\alpha$1和Benc$\alpha$2)，最后将加密的箱子和子列表发送给客户端。显然，客户端在解密接收到的列表和箱子后获得所有匹配标识符。

更新。对于关键字w和列表L '的(最多p个)新标识符6的更新请求，客户端像以前一样生成掩码m并将(w, m)发送给服务器。服务器再次从Tlen中解密x，并将Benc$\alpha$1, benc $\alpha$2发送给客户端。另外，服务器已经将箱子 Benc$\alpha$3, Benc$\alpha$4 for $\alpha$3， $\alpha$4$\leftarrow$H(w || x + 1)发送给客户端(以防不完整列表溢出)。客户端现在从解密的箱子 B$\alpha$1, B$\alpha$2中检索匹配w的旧(不完整)标识符列表L。我们区分两种情况:

\begin{enumerate}
  \item 如果L$\bigcup $L '包含超过p个标识符，则客户端设置Lnew = L$\bigcup $L '，并将(w, L)标记为B$\alpha$1, B$\alpha$2中的一个剩余球。然后，它将Lnew分成两个子列表L=p，有p个标识符，L<=p个标识符。客户端通过L2C将列表L<=p插入到箱子 B$\alpha$3, B$\alpha$4中。InsertBall((w, L<=p)， B$\alpha$3, B$\alpha$4)，并将更新(重新加密)的箱子 {Benci}4i=1，如加密列表Lenc = EncKEnc (L=p)发送到服务器。
  \item 否则，客户端像以前一样，即通过UpdateBall将新的标识L '添加到球(w, L)并重新加密接收到的箱子。
\end{enumerate}
最后，服务器用重新加密的箱子替换旧的箱子，如果它收到一个加密的列表Lnew，它将收到的列表存储在Tfull[w || x + 1] = Lenc中，并更新Tlen[w] = x + 1。

\textbf{泄漏分析。}现在，搜索和更新请求LayeredSSE清楚地泄漏了给定关键字w与$\ell$匹配标识符的子列表数量x =[$\ell$/p]。此外，当列表完成时更新泄漏。因此，更新泄密[$\ell$+ |L’|]。这正是Llen-hid模拟的泄漏。由于表Tlen和Tfull是加密的，因此可以直接将5.2节中的安全分析应用到关于泄漏函数Llen-hid的扩展方案中。

\subsubsection{优化RTT}
LayeredSSE的搜索请求只需要1个RTT，而更新请求不幸需要2个RTT。我们可以使用“装载”来将更新RTT减少到1。客户端不直接将更新请求的第二个流发送到服务器，而是将响应存储起来并等待下一个查询(更新或搜索)。在下一个查询中，客户端发送除了查询之外的存储响应。然后，服务器完成挂起的更新请求(通过存储接收到的箱子和更新表)，并随后响应查询。

\subsection{效率}
我们现在讨论LayeredSSE的效率。令wmax = N/p。服务器存储m =[wmax/(log log log $\lambda$·log log wmax)]大小为O(p log log log log($\lambda$) log log(wmax))·O($\lambda$)的箱子，表Tlen大小为log(N)，表tfull大小为p·O($\lambda$)的N/p个条目。(回想一下，单个标识符的大小为O($\lambda$)。)当N = poly($\lambda$)时，存储效率为O(1)，不需要客户端存储。此外，服务器在wordw上的搜索请求中查找4个容量不等于O (p log log(N/p))和x−1个来自Tfull的p个标识符的加密列表，其中x是明文存储匹配关键字w的文档索引所需的页数。因此，页面效率为O(log log Np)。这进一步表明，如果只插入大小不超过p的列表，LayeredSSE具有O(1)局部性。

\textbf{定理2 (LayeredSSE)。}设N为数据库DB大小的上限，p为页面大小。如果Enc是ind - cpa安全的，H被建模为随机oracle，则LayeredSSE方案是正确的，llen -hid-自适应语义安全。它具有恒定的存储效率和O (log log N/p)页面效率。如果只插入大小不超过p的列表，LayeredSSE具有恒定的局部性。

\section{泛型局部变换}
\subsection{准备工作}
合适的高效页面SSE。在Generic Local Transform中使用的高效页面方案的接口以两种方式扩展了第3节中定义的标准SSE接口。

\begin{itemize}
  \item 首先，Setup(N, p, DB)将一个新参数作为输入:页面大小p。转换将创建许多底层页面高效方案的实例，每个实例具有不同的页面大小。这就需要在设置过程中指定页面大小。
  \item 其次，在Update(w, S)过程中，第二个参数S是一组文档标识符。正确性要求是S中的所有标识符都应该添加到关键字w的列表中。Update的标准定义，其中添加了一个标识符，对应于S是单例的情况。S允许为空，在这种情况下不添加任何内容。
\end{itemize}

如果一个方案实例化了该接口，并且满足以下三个条件，我们将把这样的方案称为合适的高效页SSE。

\begin{itemize}
  \item 方案中客户端存储为O(1)。
  \item 当访问最多一个页面长度的列表时，该方案在搜索和更新过程中具有局部性O(1)。
  \item 该方案的漏洞是页面长度隐藏。
\end{itemize}
\textbf{溢出SSE。}我们引入了溢出SSE的概念。溢出SSE (OSSE)具有与标准SSE方案相同的接口和功能，除了在安装或更新操作期间，它可能拒绝存储一些文档标识符。这些标识符称为溢出标识符。在Setup和Update操作的输出中，客户端返回溢出元素的集合。与标准SSE相比，正确性定义在以下方面有所放宽:在搜索期间，只需要检索未溢出的匹配标识符。

溢出SSE的意图是，它可以用作更大SSE方案中的组件，该方案将使用单独的机制存储溢出标识符。在一些先前的SSE结构中，OSSE的使用可能被认为是隐含的。我们选择显式地引入这个概念，是因为它允许将泛型局部转换的表示清晰地分成两部分:存储大部分数据库的OSSE方案和存储溢出标识符的高效页方案数组。

\subsection{动态二维单选分配}
泛型局部转换的第一个组件是OSSE方案ClipOSSE。与之前的工作一致，我们将ClipOSSE的表示分为两部分:分配方案，它指定元素应该存储在哪里;SSE方案建立在它的基础上，它增加了一层加密、密钥管理和其他将分配方案转换为完整SSE所需的机制。

ClipOSSE中的分配方案称为1C-Alloc。与\cite{GiladAsharov2021SearchableSE}类似，分配方案是一个抽象构造，它定义了存储项的内存位置，但本身不存储任何东西。在1C-Alloc的情况下，项存储在箱子中，过程作为输出返回应存储项的箱子的索引。从1C-Alloc的角度来看，每个箱子都有无限的存储空间。更详细地说，1C-Alloc包含两个过程，Fetch和Add。

\begin{itemize}
  \item Fetch(m, w，$\ell$):给定箱子的数量m，关键字w和列表长度$\ell$，Fetch返回(超集)箱子的索引，其中匹配关键字w的元素可能存储，假设有$\ell$这样的元素。
  \item Add(m, w，$\ell$):给定相同的输入，Add返回下一个匹配关键字w的元素应该插入的箱子的索引，假设当前有$\ell$匹配元素。
\end{itemize}

其目的是在SSE Update操作期间使用Add，以便选择存储下一个列表元素的箱子;而Fetch在Search操作期间使用，以确定需要读取哪些箱子以检索所有列表元素。1C-Alloc将满足定义6.1中给出的正确性属性。请注意，箱子的数量m总是假设是2的幂。

定义6.1(正确性)。对于所有m, w，$\ell$，如果m是2的幂，那么

$\bigcup_{0 \leq i \leq \ell-1} {Add}(m, w, i) \subseteq {Fetch}(m, w, \ell)$.

为了描述1C-Alloc，在概念上将箱子分组为Super箱子很方便。对于$\ell$= 2i<=m，$\ell$-Super箱子是$\ell$个连续箱子的集合，索引形式为k·$\ell$，k·$\ell$+ 1，…， (k + 1)·$\ell$−1，对于某些k<=m/$\ell$。1-super箱子与箱子相同。注意，对于给定的$\ell$，$\ell$-Super箱子不会重叠。它们构成了箱子集的一个分区。对于$\ell$> 1，每个$\ell$-super箱子恰好包含两个$\ell$/2-super箱子。

设H为哈希函数，其输出在{1，…, m}。1C-Alloc的工作原理如下。固定一个关键字w和长度$\ell$<=m(情况$\ell$> m将在后面讨论)。让$\ell$' = 2[log$\ell$]be大于$\ell$的2的最小次幂。在输入w和$\ell$上，1C-Alloc。Fetch返回包含H(w)的(唯一的)$\ell$' -Super箱子。

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{table5.png}
  % \caption{}
  \label{table5}
\end{figure}

与此同时,1 C-Alloc.Add的设计是为了确保Add为关键字w返回的第一个$\ell$连续位置实际上包含在H(w)上方的$\ell$' -Super箱子中(也就是说，为了确保正确性)。对于第一个列表元素(当$\ell$= 0时)，Add返回箱子H(w);对于第二个元素，它返回H(w)上面的2-Super箱子中包含的另一个箱子。更一般地说，如果S是H(w)上面最小的Super箱子，包含至少$\ell$+ 1个箱子，Add将返回S中还没有接收到元素的最左边的箱子。在实践中，该箱子的索引可以根据$\ell$和H(w)的二进制分解轻松计算，就像算法3中所做的那样。(事实上，Add选择存储箱子的确切顺序是不相关的，只要它选择不同的存储箱子，并且正确性保持不变。)

当列表$\ell$的大小增长到箱子的数量m以上时，Fetch返回所有的箱子，而add选择与$\ell$mod m相同的箱子

\subsection{剪裁的单选OSSE}
ClipOSSE是通过根据1C-Alloc存储列表获得的OSSE方案，使用m = O(N/ log log N)个箱子，每个箱子包含最多$\tau$ =[$\alpha$ log log N]项，对于某些常量$\alpha$。存储箱子总是填充到阈值$\tau$，并在存储到服务器上之前进行加密。因此，从服务器的角度来看，它们是完全不透明的。包含(以加密形式)匹配每个关键字w的列表长度的表T也存储在服务器上。

给定1C-Alloc, ClipOSSE的细节很简单。下面的文本给出了一个简短的概述。由Setup生成的加密数据库本质上等同于从一个空数据库开始，并通过重复调用Update来填充它，对数据库中的每个关键字-文档对进行一次调用。因此，我们专注于搜索和更新。设置、搜索和更新的完整规范在算法4中以伪代码的形式给出

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{table6.png}
  % \caption{}
  \label{table6}
\end{figure}

\begin{itemize}
  \item Search:为了检索匹配关键字w的标识符列表，ClipOSSE调用1C-Alloc(m, w，$\ell$)来获取存储了匹配关键字w的元素的箱子索引集。客户端从服务器检索这些箱子，并解密它们以获得所需的信息。
  \item Update:为了向匹配关键字w的列表中添加一个新项，ClipOSSE调用1C-Alloc(m, w，$\ell$)来确定应该插入新列表项的箱子。客户端从服务器检索该箱子，解密它，添加新项，重新加密箱子，并将其发送回服务器。如果该箱子已经满了，则该项溢出，如第6.1节所述。
\end{itemize}

\subsection{泛型局部变换}
泛型局部变换将长度隐藏页效率SSE方案PE-SSE作为输入。输出局部SSE协议local [PE-SSE]。

为了实现Local[PE-SSE]，我们使用了两种结构。第一个结构是ClipOSSE的实例，它存储了数据库的大部分内容。第二个结构是PE-SSE的nlevel实例数组。第i个实例，表示为pe - sse，页面大小为2i。pe - sse实例用于存储溢出的元素ClipOSSE。此外，表T存储(以加密形式)匹配关键字w的列表长度，用于每个关键字8。

修复关键字w，匹配$\ell$元素。设$\ell$' = 2[log$\ell$]是比$\ell$大2的最小次方。Leti = log$\ell$'。在任何时间点，匹配w的元素都存储在两个位置:ClipOSSE和pe - sse。这两个位置都存储部分元素:ClipOSSE存储未溢出的元素，pe - sse存储溢出的元素。每个元素只存在于两个位置中的一个。

\begin{itemize}
  \item Search。在搜索操作期间，Local[PE-SSE]查询这两个结构，并结合它们的输出来检索所有匹配的元素。
  \item Update。在添加元素e的Update操作中，Local[PE-SSE]将更新请求转发给cliposse，如果元素未溢出则获取C =$\phi$ ，如果元素溢出则获取C = {e}。现在，假设[log$\ell$]=[log($\ell$+ 1)]，即在更新操作期间，与列表关联的pe - sse实例保持不变。在这种情况下，PE-SSE被更新为集合c(回想一下6.1节，长度隐藏SSE，如PE-SSE接受元素集作为update的输入)。长度隐藏属性被设计用来保证C的内容(包括它是否为空)不会泄露给服务器。现在假设[log$\ell$]<[log($\ell$+ 1)]。在这种情况下，与列表关联的PE-SSEinstance变为pe - sse +1，而不是pe - sse。客户端从pe - sse中检索当前所有溢出元素，添加C的内容，并将结果存储在pe - sse +1中。
\end{itemize}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{table7.png}
  % \caption{}
  \label{table7}
\end{figure}
\subsection{ClipOSSE溢出}
本节中的主要技术结果是关于ClipOSSE中溢出项的数量。

\textbf{定理3。}假设ClipOSSE接收到一个大小为N的数据库作为输入，使得最长列表的大小为O(N/polylogN)。对于任意常数d，存在一个ClipOSSE参数选择，使得溢出项数为O(N/ logd N)。

泛型局部转换本身使用标准SSE技术，其属性遵循前面的讨论。我们提供一份正式声明如下。

\textbf{定理4(泛型局部变换)。}设N为数据库DB大小的上限。假设PE-SSE是一个合适的页效率方案，页面效率P，存储效率S，那么local [PE-SSE]是一个正确安全的SSE方案，存储效率O(S)，局部性O(1)，读取效率P + + O(log log N)。
\bibliographystyle{unsrt}
\bibliography{ref}

\end{document}

